<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 11.8 + torch 2.1.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp310-cp310-linux_x86_64.whl#sha256=aad5dbfab3b08f1e16ac0b84ed960154cc753c3d435d5dd7d87c837121bdb6b5">flashinfer-0.0.2+cu118torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp311-cp311-linux_x86_64.whl#sha256=58df6ca2a5157e68c370a4c411ef29c4dd2fd16fe70e5dca9da16a238e28087b">flashinfer-0.0.2+cu118torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp39-cp39-linux_x86_64.whl#sha256=d89f55bb9d6758f48c94095cc7a77227e59bc28577a95223a3c9117d845e6980">flashinfer-0.0.2+cu118torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp310-cp310-linux_x86_64.whl#sha256=e2bed336ecdb0da7fece155abc4440e095728062f280b317ad20bc8dfbae4d39">flashinfer-0.0.3+cu118torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp311-cp311-linux_x86_64.whl#sha256=5d5c359885188a0c977606450b6895e84524afd0b5e1f5844209631b08d1a886">flashinfer-0.0.3+cu118torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp38-cp38-linux_x86_64.whl#sha256=1750e44f0ac00711289369f2ef52b15e2e9fa5712c4ab5bd8535eb793db0064d">flashinfer-0.0.3+cu118torch2.1-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp39-cp39-linux_x86_64.whl#sha256=52af064ed345a431eda7c2d85193b47c31f57297d3fcc2da61b9bf9b56ffa04a">flashinfer-0.0.3+cu118torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
