<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 11.8 + torch 2.1.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp310-cp310-linux_x86_64.whl#sha256=aad5dbfab3b08f1e16ac0b84ed960154cc753c3d435d5dd7d87c837121bdb6b5">flashinfer-0.0.2+cu118torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp311-cp311-linux_x86_64.whl#sha256=58df6ca2a5157e68c370a4c411ef29c4dd2fd16fe70e5dca9da16a238e28087b">flashinfer-0.0.2+cu118torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp39-cp39-linux_x86_64.whl#sha256=d89f55bb9d6758f48c94095cc7a77227e59bc28577a95223a3c9117d845e6980">flashinfer-0.0.2+cu118torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp310-cp310-linux_x86_64.whl#sha256=6b542e14b3bc3be484b53339a69978630887805e4f829b7aa44d8d39a3cbd545">flashinfer-0.0.3+cu118torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp311-cp311-linux_x86_64.whl#sha256=ab29cde3ab785431d5b947cfd421f0fede318be2d8f383a9e1b9ecc80f0c25d8">flashinfer-0.0.3+cu118torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp38-cp38-linux_x86_64.whl#sha256=f3b346b2ed98636d077c6b1e70a214aadc69be2d0af27a685bb35db71766f65c">flashinfer-0.0.3+cu118torch2.1-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.1-cp39-cp39-linux_x86_64.whl#sha256=def8bd9e6189ab0ee1cdfcc5c344d6702504c730b49635ead2fea969b61532e3">flashinfer-0.0.3+cu118torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
