<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 11.8 + torch 2.1.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp310-cp310-linux_x86_64.whl#sha256=aad5dbfab3b08f1e16ac0b84ed960154cc753c3d435d5dd7d87c837121bdb6b5">flashinfer-0.0.2+cu118torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp311-cp311-linux_x86_64.whl#sha256=58df6ca2a5157e68c370a4c411ef29c4dd2fd16fe70e5dca9da16a238e28087b">flashinfer-0.0.2+cu118torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.1-cp39-cp39-linux_x86_64.whl#sha256=d89f55bb9d6758f48c94095cc7a77227e59bc28577a95223a3c9117d845e6980">flashinfer-0.0.2+cu118torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
