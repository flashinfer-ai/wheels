<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 11.8 + torch 2.2.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp310-cp310-linux_x86_64.whl#sha256=4a2bf2ce0a83aca5fd977e48ae6d654a5ff7307625e9d6d88dee112cf280d033">flashinfer-0.0.2+cu118torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp311-cp311-linux_x86_64.whl#sha256=0aa7457ea6d80d8f6ef3497564cf2589cca4dc625730d9c4fae96118f5016b80">flashinfer-0.0.2+cu118torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp39-cp39-linux_x86_64.whl#sha256=af8c771fd022bb9f0e173fde33738e30771c0e6cacdff8286f4779a8db95111e">flashinfer-0.0.2+cu118torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp310-cp310-linux_x86_64.whl#sha256=e819900906b80f3487ff06dade2f5249c6e8fd28df0696f2259aab70d321a506">flashinfer-0.0.3+cu118torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp311-cp311-linux_x86_64.whl#sha256=b33c058ca208bc942147d5e4bb4156a545361fccba33de0689ad3c8c002bf4a2">flashinfer-0.0.3+cu118torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp38-cp38-linux_x86_64.whl#sha256=fe24e54092d217332271a98150493f9a0c752ce33b6c1230b77968a4a3e61fcc">flashinfer-0.0.3+cu118torch2.2-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp39-cp39-linux_x86_64.whl#sha256=daefbf82d8755ae76fd63b4365a50fb0fbab09c4be7f90e77cf45a9ca2b3c3f6">flashinfer-0.0.3+cu118torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
