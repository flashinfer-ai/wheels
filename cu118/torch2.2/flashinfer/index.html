<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 11.8 + torch 2.2.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp310-cp310-linux_x86_64.whl#sha256=4a2bf2ce0a83aca5fd977e48ae6d654a5ff7307625e9d6d88dee112cf280d033">flashinfer-0.0.2+cu118torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp311-cp311-linux_x86_64.whl#sha256=0aa7457ea6d80d8f6ef3497564cf2589cca4dc625730d9c4fae96118f5016b80">flashinfer-0.0.2+cu118torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp39-cp39-linux_x86_64.whl#sha256=af8c771fd022bb9f0e173fde33738e30771c0e6cacdff8286f4779a8db95111e">flashinfer-0.0.2+cu118torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp310-cp310-linux_x86_64.whl#sha256=293be54b297e8256c340a2753c52e351ca427bf5b713dea600e06ca792131b5b">flashinfer-0.0.3+cu118torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp311-cp311-linux_x86_64.whl#sha256=595e94b9fbd78b714417941449c7c87a3056503ed19280a2338f3d94527461b7">flashinfer-0.0.3+cu118torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp38-cp38-linux_x86_64.whl#sha256=4ebe7bd523d868189ffbd99c5d54527d7c06f3ba6435ccb75f858745b34d2a27">flashinfer-0.0.3+cu118torch2.2-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu118torch2.2-cp39-cp39-linux_x86_64.whl#sha256=dded147b1a7dcd500075499cd901e3568a8bbdb7b10c728a5d409ff1eea03f77">flashinfer-0.0.3+cu118torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
