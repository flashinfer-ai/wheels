<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 11.8 + torch 2.2.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp310-cp310-linux_x86_64.whl#sha256=4a2bf2ce0a83aca5fd977e48ae6d654a5ff7307625e9d6d88dee112cf280d033">flashinfer-0.0.2+cu118torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp311-cp311-linux_x86_64.whl#sha256=0aa7457ea6d80d8f6ef3497564cf2589cca4dc625730d9c4fae96118f5016b80">flashinfer-0.0.2+cu118torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu118torch2.2-cp39-cp39-linux_x86_64.whl#sha256=af8c771fd022bb9f0e173fde33738e30771c0e6cacdff8286f4779a8db95111e">flashinfer-0.0.2+cu118torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
