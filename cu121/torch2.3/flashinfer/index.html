<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.3.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.4/flashinfer-0.0.4+cu121torch2.3-cp310-cp310-linux_x86_64.whl#sha256=bd5d9c61675e4eed586e645fd52f1b40878e608a90218cf2db21ff931930ff45">flashinfer-0.0.4+cu121torch2.3-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.4/flashinfer-0.0.4+cu121torch2.3-cp311-cp311-linux_x86_64.whl#sha256=f9a68badb95e11ccce06298af23f2297c880ff01868ba97c50914244a5149493">flashinfer-0.0.4+cu121torch2.3-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.4/flashinfer-0.0.4+cu121torch2.3-cp38-cp38-linux_x86_64.whl#sha256=4dd1c779c4da55c2a256bde9b58e60dec27c7d2508d64655ac5149a29c1cce4c">flashinfer-0.0.4+cu121torch2.3-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.4/flashinfer-0.0.4+cu121torch2.3-cp39-cp39-linux_x86_64.whl#sha256=b77b9a9ba7266e40ae3f52226f70f4a769416c7dac3b967349489098784633af">flashinfer-0.0.4+cu121torch2.3-cp39-cp39-linux_x86_64.whl</a><br>
