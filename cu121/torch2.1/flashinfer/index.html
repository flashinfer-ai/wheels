<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.1.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.1-cp310-cp310-linux_x86_64.whl#sha256=3d8fc365115f1958bd6517b82bfc14bd8cfa64736d0876a0b67e9fc7ab11aaef">flashinfer-0.0.2+cu121torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.1-cp311-cp311-linux_x86_64.whl#sha256=f6e588c750f5fba29c6f49484b37e48fee9eb8c994bacdd2a2c9cff1b65cc22a">flashinfer-0.0.2+cu121torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.1-cp39-cp39-linux_x86_64.whl#sha256=c628644fb6aafc26c7431b31411c31e25e4f8fe712a6e86c028ee9550fd4ef2d">flashinfer-0.0.2+cu121torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
