<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.1.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.1-cp310-cp310-linux_x86_64.whl#sha256=3d8fc365115f1958bd6517b82bfc14bd8cfa64736d0876a0b67e9fc7ab11aaef">flashinfer-0.0.2+cu121torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.1-cp311-cp311-linux_x86_64.whl#sha256=f6e588c750f5fba29c6f49484b37e48fee9eb8c994bacdd2a2c9cff1b65cc22a">flashinfer-0.0.2+cu121torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.1-cp39-cp39-linux_x86_64.whl#sha256=c628644fb6aafc26c7431b31411c31e25e4f8fe712a6e86c028ee9550fd4ef2d">flashinfer-0.0.2+cu121torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.1-cp310-cp310-linux_x86_64.whl#sha256=bfbec64b387a2559a49c003891a92c5bb9eeb3ed7d4d0b2586c31c878521fdfe">flashinfer-0.0.3+cu121torch2.1-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.1-cp311-cp311-linux_x86_64.whl#sha256=e30ee43a0fba38b2b3962656d88728947c05403cd0deae2c85219fa3c31afd78">flashinfer-0.0.3+cu121torch2.1-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.1-cp38-cp38-linux_x86_64.whl#sha256=bd77ad943ca8737fbcfece460b11cffe6a862afb4b8ca259f0a10c27a465b833">flashinfer-0.0.3+cu121torch2.1-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.1-cp39-cp39-linux_x86_64.whl#sha256=546f5a0d85605515fb1dd8367cc6d17459b5ee6d5faf950bfedcef9df68f6ef1">flashinfer-0.0.3+cu121torch2.1-cp39-cp39-linux_x86_64.whl</a><br>
