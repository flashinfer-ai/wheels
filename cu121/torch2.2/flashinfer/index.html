<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.2.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp310-cp310-linux_x86_64.whl#sha256=b1ade690fb4fbbeb9ed961277ec46ec40b02f795ad936e33f61aa8be95b1bfbc">flashinfer-0.0.2+cu121torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp311-cp311-linux_x86_64.whl#sha256=46a29bf171afeee996091321047873d68a1ba4d14cf2184a5589c9e8ed642e2a">flashinfer-0.0.2+cu121torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp39-cp39-linux_x86_64.whl#sha256=9251daf5554543da36a4a066f36e52262ca77c6bd336ad591886a01fef8d0a1a">flashinfer-0.0.2+cu121torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
