<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.2.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp310-cp310-linux_x86_64.whl#sha256=b1ade690fb4fbbeb9ed961277ec46ec40b02f795ad936e33f61aa8be95b1bfbc">flashinfer-0.0.2+cu121torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp311-cp311-linux_x86_64.whl#sha256=46a29bf171afeee996091321047873d68a1ba4d14cf2184a5589c9e8ed642e2a">flashinfer-0.0.2+cu121torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp39-cp39-linux_x86_64.whl#sha256=9251daf5554543da36a4a066f36e52262ca77c6bd336ad591886a01fef8d0a1a">flashinfer-0.0.2+cu121torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp310-cp310-linux_x86_64.whl#sha256=59cd2513ca9e7e09c5ede16c9828884c6fd09c908569c60fc21c24ca9c5e78c1">flashinfer-0.0.3+cu121torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp311-cp311-linux_x86_64.whl#sha256=e1d64ea0f53a9d7614693652c5e83fb5100313e94241fce1fca737cc29161698">flashinfer-0.0.3+cu121torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp38-cp38-linux_x86_64.whl#sha256=60ba18c9e45c70191e5edd1bdfac54a7d43192587231435ada7e533adf9b1e4e">flashinfer-0.0.3+cu121torch2.2-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp39-cp39-linux_x86_64.whl#sha256=04483d1a39902900bca24acb304905424b9bf5fcc8c50e85cdc3c682b8febd0b">flashinfer-0.0.3+cu121torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
