<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.2.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp310-cp310-linux_x86_64.whl#sha256=b1ade690fb4fbbeb9ed961277ec46ec40b02f795ad936e33f61aa8be95b1bfbc">flashinfer-0.0.2+cu121torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp311-cp311-linux_x86_64.whl#sha256=46a29bf171afeee996091321047873d68a1ba4d14cf2184a5589c9e8ed642e2a">flashinfer-0.0.2+cu121torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.2/flashinfer-0.0.2+cu121torch2.2-cp39-cp39-linux_x86_64.whl#sha256=9251daf5554543da36a4a066f36e52262ca77c6bd336ad591886a01fef8d0a1a">flashinfer-0.0.2+cu121torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp310-cp310-linux_x86_64.whl#sha256=edf91c09420842be0b7e33f58b004452506ac79c897a5c90cfe18120eab010a1">flashinfer-0.0.3+cu121torch2.2-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp311-cp311-linux_x86_64.whl#sha256=8dfb8d533a3ae8a318184a200f428a4141c1e1c9f90aa725eb0bff9692ed2459">flashinfer-0.0.3+cu121torch2.2-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp38-cp38-linux_x86_64.whl#sha256=eec2252002bfa51489ca704585c71acfce8e90efadbf3dca6554c69a2baa7651">flashinfer-0.0.3+cu121torch2.2-cp38-cp38-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer/releases/download/v0.0.3/flashinfer-0.0.3+cu121torch2.2-cp39-cp39-linux_x86_64.whl#sha256=27ee9a94c0ea1a5581f1ff11a2e15d7c0e44a73cea7d052f47ee8883ec9f1443">flashinfer-0.0.3+cu121torch2.2-cp39-cp39-linux_x86_64.whl</a><br>
