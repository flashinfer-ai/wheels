<!DOCTYPE html>
<h1>FlashInfer Python Wheels for CUDA 12.1 + torch 2.4.0</h1>
<a href="https://github.com/flashinfer-ai/flashinfer-nightly/releases/download/0.1.6%2B4ade6f3/flashinfer-0.1.6+4ade6f3.cu121torch2.4-cp310-cp310-linux_x86_64.whl">flashinfer-0.1.6+4ade6f3.cu121torch2.4-cp310-cp310-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer-nightly/releases/download/0.1.6%2B4ade6f3/flashinfer-0.1.6+4ade6f3.cu121torch2.4-cp311-cp311-linux_x86_64.whl">flashinfer-0.1.6+4ade6f3.cu121torch2.4-cp311-cp311-linux_x86_64.whl</a><br>
<a href="https://github.com/flashinfer-ai/flashinfer-nightly/releases/download/0.1.6%2B4ade6f3/flashinfer-0.1.6+4ade6f3.cu121torch2.4-cp312-cp312-linux_x86_64.whl">flashinfer-0.1.6+4ade6f3.cu121torch2.4-cp312-cp312-linux_x86_64.whl</a><br>